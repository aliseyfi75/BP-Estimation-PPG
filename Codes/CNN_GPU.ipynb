{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1oJjnmHqNr-SPicFMD8pi8mOVAa2e091C",
      "authorship_tag": "ABX9TyPi7HhPi/xzEB5VENza/t5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliseyfi75/BP-Estimation-PPG/blob/main/Codes/CNN_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ATytUADsdIE"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RkKv1UpZgc2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58QJ7qCxt58b"
      },
      "source": [
        "xtest = np.fromfile('/content/drive/MyDrive/CPSC 533 project/xtest.dat', dtype= complex)\n",
        "xtrain = np.fromfile('/content/drive/MyDrive/CPSC 533 project/xtrain.dat', dtype= complex)\n",
        "ytest = np.fromfile('/content/drive/MyDrive/CPSC 533 project/ytest.dat', dtype= int)\n",
        "ytrain = np.fromfile('/content/drive/MyDrive/CPSC 533 project/ytrain.dat', dtype = int)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV41-o6gYtNN"
      },
      "source": [
        "def CNN_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='tanh', input_shape=(501,244,1)))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='tanh'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='tanh'))\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='tanh'))\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='tanh'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(2, activation='relu'))\n",
        "  model.compile(loss='mean_absolute_error', optimizer='adam')  \n",
        "\n",
        "  return model"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yioN-QDoZ9tj",
        "outputId": "a22433a4-9e8f-4aa6-9f2d-40c9e94f580d"
      },
      "source": [
        "xtrain = xtrain.reshape((-1,501,244,1)).real\n",
        "xtest = xtest.reshape((-1,501,244,1)).real\n",
        "ytrain = ytrain.reshape((-1,2))\n",
        "ytest = ytest.reshape((-1,2))\n",
        "\n",
        "print(xtest.shape, ytest.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23, 501, 244, 1) (23, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwnoPiFtxv8",
        "outputId": "1c5293d1-b13e-4f4c-e591-55ddb5a45f44"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  # Fit CNN model\n",
        "  model = CNN_model()\n",
        "  es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=100)\n",
        "\n",
        "  model.fit(xtrain, ytrain, batch_size=256,epochs=400, validation_split=0.2, verbose=1, callbacks=[es])\n",
        "\n",
        "  model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 102.6039 - val_loss: 105.2484\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 100.8738 - val_loss: 97.7946\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 94.0647 - val_loss: 80.1782\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 78.0283 - val_loss: 52.5892\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 54.1871 - val_loss: 47.3691\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 62.4747 - val_loss: 35.4100\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 46.7161 - val_loss: 32.9029\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 35.5136 - val_loss: 42.5395\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 45.3428 - val_loss: 40.0071\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 41.8637 - val_loss: 26.2663\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 33.9454 - val_loss: 19.1546\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 32.2052 - val_loss: 22.0566\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 40.7746 - val_loss: 19.6595\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 36.8549 - val_loss: 17.8631\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 34.0270 - val_loss: 26.5684\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 33.6662 - val_loss: 35.8879\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 33.6539 - val_loss: 33.8142\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 34.7585 - val_loss: 22.3143\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 32.8991 - val_loss: 16.0388\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 33.4581 - val_loss: 16.4222\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 34.0215 - val_loss: 15.6785\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 33.6403 - val_loss: 16.8343\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 27.4193 - val_loss: 26.0368\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 32.4046 - val_loss: 34.9747\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 34.3432 - val_loss: 32.6291\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 34.4989 - val_loss: 20.9132\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 28.5165 - val_loss: 15.0877\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 29.7189 - val_loss: 18.4411\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 36.1109 - val_loss: 15.8805\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 34.3251 - val_loss: 18.6903\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 28.5543 - val_loss: 29.5053\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 32.4900 - val_loss: 33.7160\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 34.6271 - val_loss: 28.3826\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.6503 - val_loss: 19.1870\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 26.0519 - val_loss: 15.0122\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 31.6561 - val_loss: 15.3069\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 30.9288 - val_loss: 14.7093\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.0116 - val_loss: 18.0312\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.7461 - val_loss: 26.2680\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.7409 - val_loss: 28.5950\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 27.7598 - val_loss: 22.9516\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 26.4766 - val_loss: 14.6188\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 28.7638 - val_loss: 13.4049\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 28.8450 - val_loss: 13.5968\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 28.4120 - val_loss: 18.7262\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.1964 - val_loss: 24.8300\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 29.6460 - val_loss: 26.0413\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 27.6590 - val_loss: 20.4790\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.1043 - val_loss: 14.1487\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 24.8879 - val_loss: 13.4707\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 29.3598 - val_loss: 14.3867\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 26.5944 - val_loss: 16.6527\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 24.9604 - val_loss: 18.9422\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 26.7644 - val_loss: 16.4890\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 26.5819 - val_loss: 15.4276\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.4048 - val_loss: 14.6613\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 26.6790 - val_loss: 15.1147\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 23.2691 - val_loss: 16.9362\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 23.4880 - val_loss: 18.6810\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 24.6033 - val_loss: 16.9576\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.8699 - val_loss: 17.5366\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 24.2331 - val_loss: 16.6820\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 21.3135 - val_loss: 18.5465\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 20.0348 - val_loss: 19.8495\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 24.7592 - val_loss: 18.9485\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 23.1630 - val_loss: 15.8210\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.8332 - val_loss: 15.4242\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.8688 - val_loss: 19.5792\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.8689 - val_loss: 19.9157\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 28.1632 - val_loss: 14.4091\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 24.6887 - val_loss: 13.9875\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.3306 - val_loss: 17.9516\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.2056 - val_loss: 18.9448\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.4067 - val_loss: 16.0353\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 20.9830 - val_loss: 15.6988\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.6350 - val_loss: 17.1790\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.2774 - val_loss: 19.0927\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 26.4881 - val_loss: 16.9358\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 23.1544 - val_loss: 14.7020\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 25.7157 - val_loss: 15.9772\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.2456 - val_loss: 16.7088\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 22.6081 - val_loss: 14.8506\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 23.2263 - val_loss: 16.1308\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 23.7399 - val_loss: 18.4915\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.7120 - val_loss: 18.6571\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 25.4796 - val_loss: 14.8643\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 25.6770 - val_loss: 16.5861\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.1116 - val_loss: 19.2252\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 26.7305 - val_loss: 17.1832\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 22.9796 - val_loss: 15.3231\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.8430 - val_loss: 15.1192\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 22.6646 - val_loss: 18.5540\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.2625 - val_loss: 17.6611\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 24.0068 - val_loss: 16.4510\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.6382 - val_loss: 17.4922\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 21.4886 - val_loss: 18.9236\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 24.1583 - val_loss: 16.8370\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.8056 - val_loss: 18.0817\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 21.4187 - val_loss: 17.3200\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 21.3269 - val_loss: 15.5280\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.2343 - val_loss: 16.7678\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 22.1171 - val_loss: 17.6157\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.7427 - val_loss: 17.2223\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 24.5396 - val_loss: 18.9517\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 23.5049 - val_loss: 15.9117\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.1147 - val_loss: 15.8136\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 24.5022 - val_loss: 19.2080\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.3422 - val_loss: 20.8241\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.4300 - val_loss: 16.6020\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 24.9163 - val_loss: 16.0355\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 26.8284 - val_loss: 18.6101\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.3368 - val_loss: 18.2845\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 23.1505 - val_loss: 15.1341\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 21.6092 - val_loss: 16.2706\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 22.7189 - val_loss: 19.4624\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 23.3261 - val_loss: 20.2950\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.6691 - val_loss: 16.2188\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 24.0667 - val_loss: 16.6350\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.8883 - val_loss: 17.0587\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.2472 - val_loss: 15.7154\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 24.7392 - val_loss: 17.6511\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.8207 - val_loss: 18.1273\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.7208 - val_loss: 17.5863\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 24.4661 - val_loss: 15.0360\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 22.6431 - val_loss: 16.5307\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.0008 - val_loss: 20.8959\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.5174 - val_loss: 17.7297\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.0045 - val_loss: 15.0867\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.0377 - val_loss: 15.4057\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.8578 - val_loss: 19.0837\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 26.0977 - val_loss: 19.0745\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 25.8385 - val_loss: 16.3550\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.8218 - val_loss: 15.4012\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 26.3332 - val_loss: 16.7995\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 21.7583 - val_loss: 18.8680\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 21.8808 - val_loss: 18.6258\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 23.9143 - val_loss: 17.1932\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 24.3794 - val_loss: 18.0638\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 20.6434 - val_loss: 18.7198\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 23.5879 - val_loss: 15.5789\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 24.2082 - val_loss: 15.6075\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 24.4713 - val_loss: 18.3206\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.1759 - val_loss: 16.4790\n",
            "Epoch 00143: early stopping\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_100 (Conv2D)          (None, 499, 242, 64)      640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling (None, 249, 121, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_101 (Conv2D)          (None, 247, 119, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling (None, 123, 59, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 121, 57, 64)       36928     \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 119, 55, 64)       36928     \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 117, 53, 64)       36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 58, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 96512)             0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                965130    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 1,113,504\n",
            "Trainable params: 1,113,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whORBYWdij6_",
        "outputId": "8968f198-0ed8-4d9d-bf96-7bb6dc3c8497"
      },
      "source": [
        "# Find the prediction and error\n",
        "ypred = model.predict(xtest)\n",
        "\n",
        "print(ypred, ytest)\n",
        "\n",
        "errors = abs(ytest - ypred)\n",
        "\n",
        "print('Mean Absolute Error:', np.mean(errors, axis=0))",
        "\n",
        "print('STD of error:', np.std(errors, axis=0))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7cc288378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[105.757164  61.774963]\n",
            " [107.20004   62.436287]\n",
            " [ 93.60318   54.719467]\n",
            " [147.45012   76.84673 ]\n",
            " [122.43873   66.41627 ]\n",
            " [117.192276  62.489273]\n",
            " [119.45618   65.58544 ]\n",
            " [119.45618   65.58544 ]\n",
            " [132.42686   71.42524 ]\n",
            " [120.24337   65.46341 ]\n",
            " [129.80951   69.758255]\n",
            " [131.74037   70.65908 ]\n",
            " [136.5381    74.72337 ]\n",
            " [134.71272   72.9585  ]\n",
            " [119.45618   65.58544 ]\n",
            " [125.78186   65.30934 ]\n",
            " [117.456375  64.60461 ]\n",
            " [129.86967   69.447464]\n",
            " [114.970825  63.93948 ]\n",
            " [129.35118   70.42329 ]\n",
            " [137.44933   71.467545]\n",
            " [107.411865  63.67698 ]\n",
            " [ 98.476814  54.304382]] [[137  61]\n",
            " [107  63]\n",
            " [  0   0]\n",
            " [147  69]\n",
            " [143  77]\n",
            " [138  65]\n",
            " [112  63]\n",
            " [124  75]\n",
            " [114  53]\n",
            " [166  75]\n",
            " [132  61]\n",
            " [123  66]\n",
            " [153  67]\n",
            " [131  66]\n",
            " [135  76]\n",
            " [197  93]\n",
            " [132  77]\n",
            " [125  70]\n",
            " [117  77]\n",
            " [149  79]\n",
            " [146  78]\n",
            " [120  66]\n",
            " [115  78]]\n",
            "Mean Absolute Error: [19.116061   10.88268927]\n",
            "STD of error: [17.824281   11.05354714]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
